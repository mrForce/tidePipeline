"""Upgrading parameter file

Revision ID: 98a6ad0ea1f1
Revises: dfa8cf18fe61
Create Date: 2018-08-07 09:56:14.101639

"""
from alembic import op
import sqlalchemy as sa
import filecmp
import hashlib
import glob
import os
import itertools
import re
import shutil
# revision identifiers, used by Alembic.
revision = '98a6ad0ea1f1'
down_revision = 'dfa8cf18fe61'
branch_labels = None
depends_on = None

class File:
    def __init__(self, file_path, name, row_id):
        self.file_path = file_path
        self.row_id
        self.name = name
    def get_row_id(self):
        return self.row_id
    def get_file_path(self):
        return self.file_path
    def get_name(self):
        return self.name
    def __repr__(self):
        return self.name
    def __eq__(self, other):
        return filecmp.cmp(self.get_file_path(), other.get_file_path(), False)
    def __neq__(self, other):
        return not filecmp.cmp(self.get_file_path(), other.get_file_path(), False)
    def __hash__(self):
        with open(self.get_file_path(), 'rb') as f:
            contents = f.read()
            return hash(contents)

#FileGroup was probably a really poor naming choice
class FileGroup:
    def __init__(self, files):
        #verify that they have the same content
        for x,y in itertools.combinations(files, 2):
            assert(x == y)
        self.files = files
    def get_files(self):
        return self.files
    @classmethod
    def from_files_list(files):
        sorted_files = sorted(files, key=lambda x: x.__hash__())
        groups = []
        for h, objects in itertools.groupby(sorted_files, lambda x: x.__hash__()):
            temp_groups = []
            object_list = list(objects)
            temp_groups.append([object_list[0]])
            for o in object_list[1::]:
                for temp_group in temp_groups:
                    if o == temp_group[0]:
                        temp_group[0].append(o)
                        break
                #then no current group in temp_group is equal to o
                temp_groups.append([o])
            for temp_group in temp_groups:
                groups.append(temp_group)
        return [cls(group) for group in groups]
    

def copy_file_unique_basename(filepath, destination_folder, file_extension):
    #returns the new basename
    existing_files = glob.glob(os.path.join(destination_folder, '*.' + file_extension))
    existing_basenames = [os.path.basename(file_name) for file_name in existing_files]
    file_basename = os.path.basename(file_to_copy.get_file_path())
    if file_basename in existing_basenames:
        extension_index = file_basename.rfind('.' + file_extension)
        max_version = 0
        regex = re.compile(re.escape(file_basename[0:extension_index]) + '-?(?P<version>\d*)' + file_basename[extension_index::])
        for existing_basename in existing_basenames:
            version_string = regex.match(existing_basename).group('version')
            if version_string is not None and len(version_string) > 0:
                max_version = int(version_string)
        new_file_basename = file_basename[0:extension_index] + '-' + str(max_version + 1) + file_basename[extension_index_::]
    else:
        new_file_basename = file_basename

    shutil.copy(filepath, os.path.join(destination_folder, new_file_basename))
    return new_file_basename
    
def upgrade():
    metadata = sa.MetaData()
    project_location = os.getenv('PIPELINE_PROJECT', '')
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('AssignConfidence') as batch_op:
        batch_op.add_column('AssignConfidence', sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, 'AssignConfidence', 'AssignConfidenceParameterFile', ['idParemeterFile'], ['idAssignConfidenceParameterFile'])
    with op.batch_alter_table('MSGFPlusSearch') as batch_op:
        batch_op.alter_column('MSGFPlusSearch', 'addFeatures',
                        existing_type=sa.INTEGER(),
                        nullable=True,
                        existing_server_default=sa.text("'0'"))
    with op.batch_alter_table('MaxQuantSearch') as batch_op:
        batch_op.add_column('MaxQuantSearch', sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, 'MaxQuantSearch', 'MaxQuantParameterFile', ['idParameterFile'], ['idMaxQuantParameterFile'])
    with op.batch_alter_table('Percolator') as batch_op:
        batch_op.add_column('Percolator', sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, 'Percolator', 'PercolatorParameterFile', ['idParameterFile'], ['idPercolatorParameterFile'])
    with op.batch_alter_table('TideIndex') as batch_op:
        batch_op.add_column('TideIndex', sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, 'TideIndex', 'TideIndexParameterFile', ['idParameterFile'], ['idTideIndexParameterFile'])
    with op.batch_alter_table('TideSearch') as batch_op:
        batch_op.add_column('TideSearch', sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key(None, 'TideSearch', 'TideSearchParameterFile', ['idParameterFile'], ['idTideSearchParameterFile'])
    
    searchbase = sa.Table('SearchBase', metadata, sa.Column('idSearch', sa.Integer, primary_key=True), sa.Column('searchType', sa.String(50)), sa.Column('SearchName', sa.String, unique=True))
    maxquant = sa.Table('MaxQuantSearch', metadata, sa.Column('idSearch', sa.Integer, sa.ForeignKey('SearchBase.idSearch'), primary_key=True), sa.Column('idRAW', sa.Integer, sa.ForeignKey('RAWfile.idRAWfile')), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('MaxQuantParameterFile.idMaxQuantParameterFile'), nullable=True), sa.Column('Path', sa.String, nullable=False), sa.Column('fdr', sa.String, nullable=False))
    maxquant_files = []
    for row in connection.execute(sa.select([maxquant, searchbase]).where(maxquant.c.idSearch == searchbase.c.idSearch)):
        name = row.SearchName
        location = os.path.abspath(os.path.join(project_location, row.Path, 'mqpar.xml'))
        maxquant_files.append(File(location, name, row.idSearch))
    groups = FileGroup.from_files_list(maxquant_files)
    maxquant_param_file = sa.Table('MaxQuantParameterFile', metadata, sa.Column('idMaxQuantParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))
    for group in groups:
        file_to_copy = group[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'maxquant_param_files'), 'xml')
        search_names = [x.get_name() for x.get_files() in group]
        name = input('Please give this mqpar file a name. It was used in the following MaxQuant searches: ' + ', '.join(search_names))
        new_location = os.path.join('maxquant_param_files', new_basename)
        result = connection.execute(maxquant_param_file.insert().values(Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(maxquant.update().where(maxquant.c.idSearch == row_id).values(idParameterFile = param_id))

    new_directories = ['tide_param_files/assign_confidence_param_files', 'tide_param_files/percolator_param_files', 'tide_param_files/tide_search_param_files', 'tide_param_files/tide_index_param_files']
    for new_directory in new_directories:
        new_directory_path = os.path.abspath(os.path.join(project_location, new_directory))
        print('creating directory: ' + new_directory_path)
        os.makedirs(new_directory_path)
        
    tidesearch = sa.Table('TideSearch', metadata, sa.Column('idSearch', sa.Integer, sa.ForeignKey('SearchBase.idSearch'), primary_key=True), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('TideIndex.idIndex')), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('TideSearchParameterFile.idTideSearchParameterFile')), sa.Column('paramsPath', sa.String))
    param_files = []
    for row in connection.execute(sa.select([tidesearch, searchbase]).where(tidesearch.c.idSearch == searchbase.c.idSearch)):
        name = row.SearchName
        if row.paramsPath and len(row.paramsPath) > 0:
            param_files.append(File(os.path.join(project_location, row.paramsPath), row.SearchName, row.idSearch))
    groups = FileGroup.from_files_list(param_files)
    tidesearch_param_file = sa.Table('TideSearchParameterFile', metadata, sa.Column('idTideSearchParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))
    for group in groups:
        file_to_copy = group[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'tide_search_param_files'), 'txt')
        search_names = [x.get_name() for x.get_files() in group]
        new_location = os.path.join('tide_param_files', 'tide_search_param_files', new_basename)
        name = input('Please give this Tide Search param file a name. It was used in the following Tide searches: ' + ', '.join(search_names))
        result = connection.execute(tidesearch_param_file.insert().values( Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(tidesearch.update().where(tidesearch.c.idSearch == row_id).values(idTideSearchParameterFile = param_id))
    

 
    tideindex = sa.Table('TideIndex', metadata, sa.Column('idIndex', sa.Integer, sa.ForeignKey('IndexBase.idIndex'), primary_key=True), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('TideIndexParameterFile.idTideIndexParameterFile')), sa.Column('TideIndexName', sa.String, unique=True), sa.Column('TideIndexPath'))
    tideindex_param_file = sa.Table('TideIndexParameterFile', metadata, sa.Column('idTideIndexParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))


    param_files = []
    for row in connection.execute(sa.select([tideindex])):
        name = row.Name
        path = row.Path
        param_files.append(File(os.path.join(project_location, os.path.dirname(path), 'tide-index.params.txt'), name, row.idIndex))
    groups = FileGroup.from_files_list(param_files)
    for group in groups:
        file_to_copy = group[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'tide_index_param_files'), 'txt')
        index_names = [x.get_name() for x.get_files() in group]
        new_location = os.path.join('tide_param_files', 'tide_index_param_files', new_basename)
        name = input('Please give this Tide Index param file a name. It was used in the following Tide indices: ' + ', '.join(index_names))
        result = connection.execute(tideindex_param_file.insert().values( Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(tideindex.update().where(tideindex.c.idIndex == row_id).values(idTideIndexParameterFile = param_id))



    assignconfidence = sa.Table('AssignConfidence', metadata, sa.Column('idQValue', sa.Integer, sa.ForeignKey('QValueBase.idQValue'), primary_key=True), sa.Column('AssignConfidenceOutputPath', sa.String), sa.Column('AssignConfidenceName', sa.String, unique=True), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('AssignConfidenceParameterFile.idAssignConfidenceParameterFile')))
    assignconfidence_parameter_file = sa.Table('AssignConfidenceParameterFile', metadata, sa.Column('idAssignConfidenceParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))

    param_files = []
    for row in connection.execute(sa.select([assignconfidence])):
        name = row.AssignConfidenceName
        path = row.AssignConfidenceOutputPath
        param_files.append(File(os.path.join(project_location, path, 'assign-confidence.params.txt'), name, row.idQValue))
    groups = FileGroup.from_files_list(param_files)
    for group in groups:
        file_to_copy = group[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'assign_confidence_param_files'), 'txt')
        assignconfidence_names = [x.get_name() for x.get_files() in group]
        new_location = os.path.join('tide_param_files', 'assign_confidence_param_files', new_basename)
        name = input('Please give this Assign-Confidence param file a name. It was used in the following Assign-Confidence runs: ' + ', '.join(assignconfidence_names))
        result = connection.execute(assignconfidence_param_file.insert().values(Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(assignconfidence.update().where(assignconfidence.c.idQValue == row_id).values(idAssignConfidenceParameterFile = param_id))


    percolator = sa.Table('Percolator', metadata, sa.Column('idQValue', sa.Integer, ForeignKey('QValueBase.idQValue'), primary_key=True), sa.Column('PercolatorName', sa.String, unique=True), sa.Column('inputParamFilePath', sa.String), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('PercolatorParameterFile.idPercolatorParameterFile')))

    percolator_parameter_file = sa.Table('PercolatorParameterFile', metadata, sa.Column('idPercolatorParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))


    param_files = []
    for row in connection.execute(sa.select([percolator])):
        name = row.PercolatorName
        path = row.inputParamFilePath
        param_files.append(File(os.path.join(project_location, path), name, row.idQValue))
    groups = FileGroup.from_files_list(param_files)
    for group in groups:
        file_to_copy = group[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'percolator_param_files'), 'txt')
        percolator_names = [x.get_name() for x.get_files() in group]
        new_location = os.path.join('tide_param_files', 'percolator_param_files', new_basename)
        name = input('Please give this Percolator param file a name. It was used in the following Percolator runs: ' + ', '.join(percolator_names))
        result = connection.execute(percolator_param_file.insert().values(Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(percolator.update().where(percolator.c.idQValue == row_id).values(idPercolatorParameterFile = param_id))

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'TideSearch', type_='foreignkey')
    op.drop_column('TideSearch', 'idParameterFile')
    op.drop_constraint(None, 'TideIndex', type_='foreignkey')
    op.drop_column('TideIndex', 'idParameterFile')
    op.drop_constraint(None, 'Percolator', type_='foreignkey')
    op.drop_column('Percolator', 'idParameterFile')
    op.drop_constraint(None, 'MaxQuantSearch', type_='foreignkey')
    op.drop_column('MaxQuantSearch', 'idParameterFile')
    op.alter_column('MSGFPlusSearch', 'addFeatures',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text("'0'"))
    op.drop_constraint(None, 'AssignConfidence', type_='foreignkey')
    op.drop_column('AssignConfidence', 'idParameterFile')
    # ### end Alembic commands ###
