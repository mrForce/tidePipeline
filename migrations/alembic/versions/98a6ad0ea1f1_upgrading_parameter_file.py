"""Upgrading parameter file

Revision ID: 98a6ad0ea1f1
Revises: dfa8cf18fe61
Create Date: 2018-08-07 09:56:14.101639

"""
from alembic import op
import sqlalchemy as sa
from num2words import num2words
import filecmp
import hashlib
import glob
import os
import itertools
import re
import shutil
# revision identifiers, used by Alembic.
revision = '98a6ad0ea1f1'
down_revision = 'dfa8cf18fe61'
branch_labels = None
depends_on = None

class File:
    def __init__(self, file_path, name, row_id):
        self.file_path = file_path
        self.row_id = row_id
        self.name = name
    def get_row_id(self):
        return self.row_id
    def get_file_path(self):
        return self.file_path
    def get_name(self):
        return self.name
    def __repr__(self):
        return self.name
    def __eq__(self, other):
        return filecmp.cmp(self.get_file_path(), other.get_file_path(), False)
    def __neq__(self, other):
        return not filecmp.cmp(self.get_file_path(), other.get_file_path(), False)
    def __hash__(self):
        with open(self.get_file_path(), 'rb') as f:
            contents = f.read()
            return hash(contents)

#FileGroup was probably a really poor naming choice
class FileGroup:
    def __init__(self, files):
        #verify that they have the same content
        for x,y in itertools.combinations(files, 2):
            assert(x == y)
        self.files = files
    def get_files(self):
        return self.files
    @classmethod
    def from_files_list(cls, files):
        sorted_files = sorted(files, key=lambda x: x.__hash__())
        groups = []
        for h, objects in itertools.groupby(sorted_files, lambda x: x.__hash__()):
            temp_groups = []
            object_list = list(objects)
            temp_groups.append([object_list[0]])
            for o in object_list[1::]:
                for temp_group in temp_groups:
                    if o == temp_group[0]:
                        temp_group.append(o)
                        break
                #then no current group in temp_group is equal to o
                temp_groups.append([o])
            for temp_group in temp_groups:
                groups.append(temp_group)
        return [cls(group) for group in groups]
    

def copy_file_unique_basename(filepath, destination_folder, file_extension):
    #returns the new basename
    existing_files = glob.glob(os.path.join(destination_folder, '*.' + file_extension))
    existing_basenames = [os.path.basename(file_name) for file_name in existing_files]
    file_basename = os.path.basename(filepath)
    if file_basename in existing_basenames:
        extension_index = file_basename.rfind('.' + file_extension)
        max_version = 0
        regex_string = re.escape(file_basename[0:extension_index]) + '-?(?P<version>\d*)' + file_basename[extension_index::]
        regex = re.compile(regex_string)
        print('regex string: ' + regex_string)
        
        for existing_basename in existing_basenames:
            print('existing basename: ' + existing_basename)
            version_string_match = regex.match(existing_basename)
            if version_string_match is not None:
                version_string = version_string_match.group('version')
                if version_string is not None and len(version_string) > 0:
                    if int(version_string) > max_version:
                        max_version = int(version_string)

        print('max version: ' + str(max_version))
        new_file_basename = file_basename[0:extension_index] + '-' + str(max_version + 1) + file_basename[extension_index::]
    else:
        new_file_basename = file_basename

    shutil.copy(filepath, os.path.join(destination_folder, new_file_basename))
    return new_file_basename
    
def upgrade():
    metadata = sa.MetaData()
    connection = op.get_bind()
    project_location = os.getenv('PIPELINE_PROJECT', '')
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('AssignConfidence') as batch_op:
        batch_op.add_column(sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('idParameterFile', 'AssignConfidenceParameterFile', ['idParemeterFile'], ['idAssignConfidenceParameterFile'])
    with op.batch_alter_table('MSGFPlusSearch') as batch_op:
        batch_op.alter_column('addFeatures',
                        existing_type=sa.INTEGER(),
                        nullable=True,
                        existing_server_default=sa.text("'0'"))
    with op.batch_alter_table('MaxQuantSearch') as batch_op:
        batch_op.add_column(sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('idParameterFile', 'MaxQuantParameterFile', ['idParameterFile'], ['idMaxQuantParameterFile'])
    with op.batch_alter_table('Percolator') as batch_op:
        batch_op.add_column(sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('idParameterFile',  'PercolatorParameterFile', ['idParameterFile'], ['idPercolatorParameterFile'])
    with op.batch_alter_table('TideIndex') as batch_op:
        batch_op.add_column(sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('idParameterFile', 'TideIndexParameterFile', ['idParameterFile'], ['idTideIndexParameterFile'])
    with op.batch_alter_table('TideSearch') as batch_op:
        batch_op.add_column(sa.Column('idParameterFile', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('idParameterFile',  'TideSearchParameterFile', ['idParameterFile'], ['idTideSearchParameterFile'])
    
    searchbase = sa.Table('SearchBase', metadata, sa.Column('idSearch', sa.Integer, primary_key=True), sa.Column('searchType', sa.String(50)), sa.Column('SearchName', sa.String, unique=True))
    maxquant_param_file = sa.Table('MaxQuantParameterFile', metadata, sa.Column('idMaxQuantParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, nullable=False), sa.Column('Comment', sa.String))
    maxquant = sa.Table('MaxQuantSearch', metadata, sa.Column('idSearch', sa.Integer, sa.ForeignKey('SearchBase.idSearch'), primary_key=True),  sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('MaxQuantParameterFile.idMaxQuantParameterFile'), nullable=True), sa.Column('Path', sa.String, nullable=False), sa.Column('fdr', sa.String, nullable=False))
    maxquant_param_files = {}
    for row in connection.execute(sa.select([maxquant_param_file])):
        maxquant_param_files[row.Name] = row.idMaxQuantParameterFile
    maxquant_files = []
    for row in connection.execute(sa.select([maxquant, searchbase]).where(maxquant.c.idSearch == searchbase.c.idSearch).reduce_columns()):
        name = row.SearchName
        if len(maxquant_param_files.items()) == 1:
            print('There is only 1 maxquant parameter file. Going to connect search: ' + name + ' with param file: ' + list(maxquant_param_files.keys())[0])
            connection.execute(maxquant.update().where(maxquant.c.idSearch == row.idSearch).values(idParameterFile = list(maxquant_param_files.values())[0]))
        else:
            names_to_pick = list(maxquant_param_files.keys())
            while True:
                print('You need to select a maxquant parameter file to pair with the maxquant search: ' + name)
                i = 0
                for x in names_to_pick:
                    print(str(i + 1) + ') ' + x)
                    i += 1
                selection = input('Please select: ')
                if selection.isdigit():
                    selection_int = int(selection)
                    if selection_int in list(range(1, len(names_to_pick) + 1)):
                        connection.execute(maxquant.update().where(maxquant.c.idSearch == row.idSearch).values(idParameterFile = maxquant_param_files[names_to_pick[i - 1]]))
                        break
                    else:
                        print('Not in range. Try again')
                else:
                    print('Not an integer. Try again')


    new_directories = ['tide_param_files/assign_confidence_param_files', 'tide_param_files/percolator_param_files', 'tide_param_files/tide_search_param_files', 'tide_param_files/tide_index_param_files']
    for new_directory in new_directories:
        new_directory_path = os.path.abspath(os.path.join(project_location, new_directory))
        print('creating directory: ' + new_directory_path)
        os.makedirs(new_directory_path, exist_ok=True)
    
    tidesearch_param_file = sa.Table('TideSearchParameterFile', metadata, sa.Column('idTideSearchParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))    
    tidesearch = sa.Table('TideSearch', metadata, sa.Column('idSearch', sa.Integer, sa.ForeignKey('SearchBase.idSearch'), primary_key=True),  sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('TideSearchParameterFile.idTideSearchParameterFile')), sa.Column('paramsPath', sa.String), sa.Column('targetPath', sa.String))
    param_files = []
    for row in connection.execute(sa.select([tidesearch, searchbase]).where(tidesearch.c.idSearch == searchbase.c.idSearch).reduce_columns()):
        name = row.SearchName
        
        if row.paramsPath and len(row.paramsPath) > 0:
            if os.path.isfile(os.path.join(project_location, row.paramsPath)):
                param_files.append(File(os.path.join(project_location, row.paramsPath), row.SearchName, row.idSearch))
            else:
                param_files.append(File(os.path.join(project_location, os.path.dirname(row.targetPath), 'tide-search.params.txt'), row.SearchName, row.idSearch))
    groups = FileGroup.from_files_list(param_files)
    i = 0
    for group in groups:
        file_to_copy = group.get_files()[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'tide_search_param_files'), 'txt')
        search_names = [x.get_name() for x in group.get_files()]
        new_location = os.path.join('tide_param_files', 'tide_search_param_files', new_basename)
        #name = input('Please give this Tide Search param file a name. It was used in the following Tide searches: ' + ', '.join(search_names) + ': ')
        name = num2words(i)
        i += 1
        result = connection.execute(tidesearch_param_file.insert().values( Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(tidesearch.update().where(tidesearch.c.idSearch == row_id).values(idParameterFile = param_id))
    

    tideindex_param_file = sa.Table('TideIndexParameterFile', metadata, sa.Column('idTideIndexParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))
    tideindex = sa.Table('TideIndex', metadata, sa.Column('idIndex', sa.Integer, sa.ForeignKey('IndexBase.idIndex'), primary_key=True), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('TideIndexParameterFile.idTideIndexParameterFile')), sa.Column('TideIndexName', sa.String, unique=True), sa.Column('TideIndexPath'))
    


    param_files = []
    for row in connection.execute(sa.select([tideindex])):
        name = row.TideIndexName
        path = row.TideIndexPath
        param_files.append(File(os.path.join(project_location, os.path.dirname(path), 'tide-index.params.txt'), name, row.idIndex))
    groups = FileGroup.from_files_list(param_files)
    i = 0
    for group in groups:
        file_to_copy = group.get_files()[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'tide_index_param_files'), 'txt')
        index_names = [x.get_name() for x in group.get_files()]
        new_location = os.path.join('tide_param_files', 'tide_index_param_files', new_basename)
        #name = input('Please give this Tide Index param file a name. It was used in the following Tide indices: ' + ', '.join(index_names) + ': ')
        name = num2words(i)
        i += 1
        result = connection.execute(tideindex_param_file.insert().values( Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(tideindex.update().where(tideindex.c.idIndex == row_id).values(idParameterFile = param_id))



    assignconfidence = sa.Table('AssignConfidence', metadata, sa.Column('idQValue', sa.Integer, sa.ForeignKey('QValueBase.idQValue'), primary_key=True), sa.Column('AssignConfidenceOutputPath', sa.String), sa.Column('AssignConfidenceName', sa.String, unique=True), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('AssignConfidenceParameterFile.idAssignConfidenceParameterFile')))
    assignconfidence_parameter_file = sa.Table('AssignConfidenceParameterFile', metadata, sa.Column('idAssignConfidenceParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))

    param_files = []
    for row in connection.execute(sa.select([assignconfidence])):
        name = row.AssignConfidenceName
        path = row.AssignConfidenceOutputPath
        param_files.append(File(os.path.join(project_location, path, 'assign-confidence.params.txt'), name, row.idQValue))
    groups = FileGroup.from_files_list(param_files)
    i = 0
    for group in groups:
        file_to_copy = group.get_files()[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'assign_confidence_param_files'), 'txt')
        assignconfidence_names = [x.get_name() for x in group.get_files()]
        new_location = os.path.join('tide_param_files', 'assign_confidence_param_files', new_basename)
        #name = input('Please give this Assign-Confidence param file a name. It was used in the following Assign-Confidence runs: ' + ', '.join(assignconfidence_names) + ': ')
        name = num2words(i)
        i += 1
        result = connection.execute(assignconfidence_parameter_file.insert().values(Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(assignconfidence.update().where(assignconfidence.c.idQValue == row_id).values(idParameterFile = param_id))

    percolator_parameter_file = sa.Table('PercolatorParameterFile', metadata, sa.Column('idPercolatorParameterFile', sa.Integer, primary_key=True), sa.Column('Name', sa.String, unique=True, nullable=False), sa.Column('Path', sa.String, unique=True, nullable=False), sa.Column('Comment', sa.String))
    percolator = sa.Table('Percolator', metadata, sa.Column('idQValue', sa.Integer, sa.ForeignKey('QValueBase.idQValue'), primary_key=True), sa.Column('PercolatorName', sa.String, unique=True), sa.Column('inputParamFilePath', sa.String), sa.Column('idParameterFile', sa.Integer, sa.ForeignKey('PercolatorParameterFile.idPercolatorParameterFile')))

    


    param_files = []
    for row in connection.execute(sa.select([percolator])):
        name = row.PercolatorName
        path = row.inputParamFilePath
        param_files.append(File(os.path.join(project_location, path), name, row.idQValue))
    groups = FileGroup.from_files_list(param_files)
    i = 0
    for group in groups:
        file_to_copy = group.get_files()[0]
        new_basename = copy_file_unique_basename(file_to_copy.get_file_path(), os.path.join(project_location, 'tide_param_files', 'percolator_param_files'), 'params')
        percolator_names = [x.get_name() for x in group.get_files()]
        new_location = os.path.join('tide_param_files', 'percolator_param_files', new_basename)
        #name = input('Please give this Percolator param file a name. It was used in the following Percolator runs: ' + ', '.join(percolator_names) + ': ')
        name = num2words(i)
        i += 1
        result = connection.execute(percolator_parameter_file.insert().values(Name = name, Path = new_location, Comment = 'Created by alembic upgrade'))
        param_id = result.inserted_primary_key[0]
        for f in group.get_files():
            row_id = f.get_row_id()
            connection.execute(percolator.update().where(percolator.c.idQValue == row_id).values(idParameterFile = param_id))

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'TideSearch', type_='foreignkey')
    op.drop_column('TideSearch', 'idParameterFile')
    op.drop_constraint(None, 'TideIndex', type_='foreignkey')
    op.drop_column('TideIndex', 'idParameterFile')
    op.drop_constraint(None, 'Percolator', type_='foreignkey')
    op.drop_column('Percolator', 'idParameterFile')
    op.drop_constraint(None, 'MaxQuantSearch', type_='foreignkey')
    op.drop_column('MaxQuantSearch', 'idParameterFile')
    op.alter_column('MSGFPlusSearch', 'addFeatures',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text("'0'"))
    op.drop_constraint(None, 'AssignConfidence', type_='foreignkey')
    op.drop_column('AssignConfidence', 'idParameterFile')
    # ### end Alembic commands ###
